import os
import sys
import torch
import yaml
import argparse
import random
import copy
import numpy as np
from PIL import Image
from transformers import BertTokenizer

# --- Diffusers & PEFT Imports ---
from diffusers import (
    StableDiffusionControlNetPipeline, 
    ControlNetModel, 
    UniPCMultistepScheduler,
    UNet2DConditionModel
)
from peft import PeftModel

# ==========================================
# 1. ç¯å¢ƒä¸è·¯å¾„è®¾ç½®
# ==========================================
# è·å–å½“å‰è„šæœ¬è·¯å¾„ï¼Œç¡®ä¿èƒ½å¯¼å…¥é¡¹ç›®æ¨¡å—
current_script_path = os.path.abspath(__file__)
project_root = os.path.dirname(current_script_path)
sys.path.insert(0, project_root)

try:
    # Stage 1 Imports
    from models.poem2layout import Poem2LayoutGenerator
    from inference.greedy_decode import greedy_decode_poem_layout
    
    # Stage 2 Imports
    from stage2_generation.utils.ink_mask import InkWashMaskGenerator
except ImportError as e:
    print(f"[Error] æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿è„šæœ¬ä½äºé¡¹ç›®æ ¹ç›®å½•ï¼Œå¹¶ä¸” models/, inference/, stage2_generation/ æ–‡ä»¶å¤¹å­˜åœ¨ã€‚")
    sys.exit(1)

# ==========================================
# 2. è¾…åŠ©å‡½æ•° (Stage 1)
# ==========================================

def calculate_total_iou(boxes_tensor):
    """è®¡ç®—æ‰€æœ‰æ¡†çš„æ€»é‡å é¢ç§¯"""
    if boxes_tensor.size(0) < 2: return 0.0
    x1 = boxes_tensor[:, 0] - boxes_tensor[:, 2] / 2
    x2 = boxes_tensor[:, 0] + boxes_tensor[:, 2] / 2
    y1 = boxes_tensor[:, 1] - boxes_tensor[:, 3] / 2
    y2 = boxes_tensor[:, 1] + boxes_tensor[:, 3] / 2
    
    n = boxes_tensor.size(0)
    total_inter = 0.0
    for i in range(n):
        for j in range(i + 1, n):
            xx1 = max(x1[i], x1[j]); yy1 = max(y1[i], y1[j])
            xx2 = min(x2[i], x2[j]); yy2 = min(y2[i], y2[j])
            w = max(0, xx2 - xx1); h = max(0, yy2 - yy1)
            total_inter += w * h
    return total_inter

def apply_random_symmetry(layout, device='cpu', attempt_prob=0.5):
    """å°è¯•å¯¹å¸ƒå±€è¿›è¡Œæ°´å¹³ç¿»è½¬ï¼ˆå¢åŠ æ„å›¾å¤šæ ·æ€§ï¼‰"""
    if not layout: return layout
    # æå– Box æ•°æ®ç”¨äºè®¡ç®— IoU
    boxes_data = [list(item[1:5]) for item in layout] 
    boxes_tensor = torch.tensor(boxes_data, dtype=torch.float32).to(device)
    initial_iou = calculate_total_iou(boxes_tensor)
    
    new_layout = copy.deepcopy(layout)
    current_boxes = boxes_tensor.clone()
    
    indices = list(range(len(layout)))
    random.shuffle(indices)
    
    for idx in indices:
        if random.random() > attempt_prob: continue
        original_item = new_layout[idx]
        original_box = current_boxes[idx].clone()
        
        # ç¿»è½¬é€»è¾‘: cx' = 1 - cx
        new_cx = 1.0 - original_item[1]
        
        # ç¿»è½¬æ€åŠ¿: Bias_X (Rotation Bias) å–å
        item_list = list(original_item)
        item_list[1] = new_cx
        
        # å‡è®¾ layout item æ ¼å¼: [cls, cx, cy, w, h, bx, by, rot, flow]
        if len(item_list) >= 9:
            item_list[5] = -item_list[5] # bias_x å–å
            item_list[7] = -item_list[7] # rotation é•œåƒ
        
        current_boxes[idx, 0] = new_cx
        new_iou = calculate_total_iou(current_boxes)
        
        # åªæœ‰å½“ç¿»è½¬ä¸å¯¼è‡´ä¸¥é‡çš„é‡å å¢åŠ æ—¶æ‰æ¥å—
        if new_iou <= initial_iou + 1e-4: 
            new_layout[idx] = tuple(item_list)
            initial_iou = new_iou 
        else:
            current_boxes[idx] = original_box # æ’¤é”€
            
    return new_layout

# ==========================================
# 3. æ¨¡å‹åŠ è½½ç±»
# ==========================================

class ShanshuiPipeline:
    def __init__(self, args):
        self.device = args.device
        self.args = args
        
        print("\nğŸš€ åˆå§‹åŒ–å…¨æµç¨‹ç”Ÿæˆç®¡çº¿...")
        
        # --- åŠ è½½ Stage 1: å¸ƒå±€ç”Ÿæˆæ¨¡å‹ ---
        self.layout_model, self.tokenizer = self._load_layout_model()
        
        # --- åŠ è½½ Stage 2: ç»˜ç”»ç”Ÿæˆæ¨¡å‹ (PEFT + ControlNet) ---
        self.sd_pipe = self._load_sd_pipeline()
        
        # --- å·¥å…·: å¢¨éŸµæ©ç ç”Ÿæˆå™¨ ---
        self.mask_generator = InkWashMaskGenerator(width=args.width, height=args.height)
        
    def _load_layout_model(self):
        print(f"   [Stage 1] åŠ è½½å¸ƒå±€æ¨¡å‹é…ç½®: {self.args.layout_config}")
        with open(self.args.layout_config, "r") as f:
            config = yaml.safe_load(f)
        model_config = config['model']
        
        tokenizer = BertTokenizer.from_pretrained(model_config['bert_path'])
        
        model = Poem2LayoutGenerator(
            bert_path=model_config['bert_path'],
            num_classes=model_config['num_classes'],
            hidden_size=model_config['hidden_size'],
            bb_size=model_config['bb_size'],
            decoder_layers=model_config['decoder_layers'],
            decoder_heads=model_config['decoder_heads'],
            dropout=model_config['dropout'],
            latent_dim=model_config.get('latent_dim', 32)
        )
        
        print(f"   [Stage 1] åŠ è½½æƒé‡: {self.args.layout_checkpoint}")
        checkpoint = torch.load(self.args.layout_checkpoint, map_location=self.device)
        
        # å¤„ç† state_dict é”®å (ç§»é™¤ module. å‰ç¼€)
        state_dict = checkpoint['model_state_dict']
        new_state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}
        
        model.load_state_dict(new_state_dict)
        model.to(self.device)
        model.eval()
        return model, tokenizer

    def _load_sd_pipeline(self):
        print(f"   [Stage 2] åŠ è½½åŸºç¡€æ¨¡å‹: {self.args.base_sd_path}")
        
        # 1. åŠ è½½ Base UNet
        unet = UNet2DConditionModel.from_pretrained(
            self.args.base_sd_path, subfolder="unet", torch_dtype=torch.float16
        )
        
        # 2. æŒ‚è½½ PEFT LoRA (æ ¸å¿ƒæ­¥éª¤)
        lora_path = os.path.join(self.args.sd_checkpoint_dir, "unet_lora")
        print(f"   [Stage 2] æŒ‚è½½ LoRA æƒé‡: {lora_path}")
        try:
            unet = PeftModel.from_pretrained(unet, lora_path)
            unet = unet.merge_and_unload() # ç‰©ç†èåˆ
            print("   âœ… LoRA èåˆæˆåŠŸ")
        except Exception as e:
            print(f"   âŒ LoRA æŒ‚è½½å¤±è´¥: {e}")
            sys.exit(1)
            
        # 3. åŠ è½½ ControlNet
        controlnet_path = os.path.join(self.args.sd_checkpoint_dir, "controlnet_structure")
        print(f"   [Stage 2] åŠ è½½ ControlNet: {controlnet_path}")
        controlnet = ControlNetModel.from_pretrained(controlnet_path, torch_dtype=torch.float16)
        
        # 4. ç»„è£… Pipeline
        pipe = StableDiffusionControlNetPipeline.from_pretrained(
            self.args.base_sd_path,
            unet=unet, # æ³¨å…¥äº† LoRA çš„ UNet
            controlnet=controlnet,
            torch_dtype=torch.float16,
            safety_checker=None
        ).to(self.device)
        
        pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)
        # å¯ç”¨æ˜¾å­˜ä¼˜åŒ–
        if self.device == 'cuda':
            pipe.enable_model_cpu_offload()
            
        return pipe

    # [NEW] å°† Latents è§£ç ä¸ºå¯è§å›¾ç‰‡çš„è¾…åŠ©å‡½æ•°
    def decode_latents_to_image(self, latents):
        # SD é»˜è®¤ç¼©æ”¾å› å­
        scaling_factor = self.sd_pipe.vae.config.scaling_factor
        latents = 1 / scaling_factor * latents
        
        with torch.no_grad():
            image = self.sd_pipe.vae.decode(latents).sample

        image = (image / 2 + 0.5).clamp(0, 1)
        image = image.cpu().permute(0, 2, 3, 1).float().numpy()
        image = (image * 255).round().astype("uint8")
        return Image.fromarray(image[0])

    def generate(self, poem_text, seed=None, save_intermediates_dir=None):
        if seed is not None:
            random.seed(seed)
            torch.manual_seed(seed)
            generator = torch.Generator(device=self.device).manual_seed(seed)
        else:
            generator = None

        print(f"\nğŸ¨ æ­£åœ¨å¤„ç†è¯—å¥: ã€{poem_text}ã€‘")
        
        # --- Step 1: Layout Generation ---
        print("   1. ç”Ÿæˆå¸ƒå±€ (Layout)...")
        layout = greedy_decode_poem_layout(
            model=self.layout_model, 
            tokenizer=self.tokenizer, 
            poem=poem_text,
            max_elements=self.args.max_elements, 
            device=self.device
        )
        
        if not layout:
            print("   âš ï¸ è­¦å‘Š: æœªç”Ÿæˆæœ‰æ•ˆå¸ƒå±€ï¼Œè·³è¿‡ã€‚")
            return None, None
            
        # éšæœºå¯¹ç§°å¢å¼º
        layout = apply_random_symmetry(layout, device=self.device, attempt_prob=0.6)
        print(f"      ç”Ÿæˆäº† {len(layout)} ä¸ªæ„è±¡å…ƒç´ ã€‚")

        # --- Step 2: Mask Generation ---
        print("   2. ç”Ÿæˆå¢¨éŸµæ©ç  (Ink Mask)...")
        layout_list = [list(item) for item in layout]
        control_mask = self.mask_generator.convert_boxes_to_mask(layout_list)

        # --- Step 3: Image Diffusion ---
        print("   3. æ‰©æ•£ç”Ÿæˆç”»ä½œ (Diffusion)...")
        n_prompt = "çœŸå®ç…§ç‰‡ï¼Œæ‘„å½±æ„Ÿï¼Œ3Dæ¸²æŸ“ï¼Œé”åˆ©è¾¹ç¼˜ï¼Œç°ä»£æ„Ÿï¼Œé²œè‰³è‰²å½©ï¼Œæ²¹ç”»ï¼Œæ°´ç²‰ç”»ï¼Œæ‚ä¹±ï¼Œæ¨¡ç³Šï¼Œé‡å½±"
        
        # --- [NEW] å®šä¹‰å›è°ƒå‡½æ•°ä¿å­˜ä¸­é—´è¿‡ç¨‹ ---
        def callback_fn(step: int, timestep: int, latents: torch.FloatTensor):
            # æ¯ 5 æ­¥ä¿å­˜ä¸€æ¬¡ï¼Œæˆ–è€…æ˜¯æœ€åä¸€æ­¥
            if save_intermediates_dir and (step % 5 == 0 or step == self.args.steps - 1):
                image = self.decode_latents_to_image(latents)
                step_str = str(step).zfill(3)
                save_path = os.path.join(save_intermediates_dir, f"step_{step_str}.png")
                image.save(save_path)

        callback = callback_fn if save_intermediates_dir else None
        # å¦‚æœè®¾ç½®äº†å›è°ƒï¼Œæ­¥é•¿è®¾ä¸º1ä»¥ç¡®ä¿èƒ½æ•æ‰
        callback_steps = 1

        image = self.sd_pipe(
            prompt=poem_text,
            image=control_mask,
            negative_prompt=n_prompt,
            num_inference_steps=self.args.steps,
            guidance_scale=self.args.guidance,
            controlnet_conditioning_scale=self.args.control_scale,
            width=self.args.width,
            height=self.args.height,
            generator=generator,
            callback=callback,          # æ³¨å…¥å›è°ƒ
            callback_steps=callback_steps # è®¾ç½®é¢‘ç‡
        ).images[0]
        
        return image, control_mask

# ==========================================
# 4. ä¸»ç¨‹åºå…¥å£
# ==========================================

def main():
    parser = argparse.ArgumentParser(description="Poem2Painting End-to-End Inference")
    
    # è·¯å¾„å‚æ•°
    parser.add_argument('--layout_checkpoint', type=str, required=True, help="Stage 1 Poem2Layout .pth æ–‡ä»¶è·¯å¾„")
    parser.add_argument('--sd_checkpoint_dir', type=str, required=True, help="Stage 2 Checkpoint ç›®å½• (åŒ…å« unet_lora å’Œ controlnet_structure)")
    parser.add_argument('--base_sd_path', type=str, default="/home/610-sty/huggingface/Taiyi-Stable-Diffusion-1B-Chinese-v0.1", help="å¤ªä¹™ SD åº•åº§æ¨¡å‹è·¯å¾„")
    parser.add_argument('--layout_config', type=str, default="configs/default.yaml", help="å¸ƒå±€æ¨¡å‹é…ç½®æ–‡ä»¶")
    
    # ç”Ÿæˆå‚æ•°
    parser.add_argument('--poem', type=str, default="ä¸¤åªé»„é¹‚é¸£ç¿ æŸ³ï¼Œä¸€è¡Œç™½é¹­ä¸Šé’å¤©ã€‚", help="è¾“å…¥è¯—å¥")
    parser.add_argument('--output_dir', type=str, default="outputs/final_results", help="ç»“æœä¿å­˜ç›®å½•")
    parser.add_argument('--width', type=int, default=512)
    parser.add_argument('--height', type=int, default=512)
    parser.add_argument('--steps', type=int, default=30)
    
    # [FIXED] ä¿®æ­£å‚æ•°ç±»å‹é”™è¯¯ type.float -> type=float
    parser.add_argument('--guidance', type=float, default=7.5)
    parser.add_argument('--control_scale', type=float, default=0.8)
    
    parser.add_argument('--max_elements', type=int, default=30)
    parser.add_argument('--device', type=str, default="cuda")
    parser.add_argument('--seed', type=int, default=None)
    
    # [NEW] æ˜¯å¦ä¿å­˜ä¸­é—´è¿‡ç¨‹
    parser.add_argument('--save_intermediates', action='store_true', help="å¼€å¯åï¼Œå°†åœ¨è¾“å‡ºç›®å½•åˆ›å»ºå­æ–‡ä»¶å¤¹ä¿å­˜æ‰©æ•£è¿‡ç¨‹å›¾")
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–ç®¡çº¿
    pipeline = ShanshuiPipeline(args)
    
    # æ‰§è¡Œç”Ÿæˆ
    os.makedirs(args.output_dir, exist_ok=True)
    
    # ç®€å•çš„æ–‡ä»¶åæ¸…ç†
    safe_name = "".join([c for c in args.poem if c.isalnum()])[:10]
    if not safe_name: safe_name = "demo_result"

    # å¦‚æœéœ€è¦ä¿å­˜ä¸­é—´è¿‡ç¨‹ï¼Œåˆ›å»ºå­ç›®å½•
    intermediates_dir = None
    if args.save_intermediates:
        intermediates_dir = os.path.join(args.output_dir, f"{safe_name}_steps")
        os.makedirs(intermediates_dir, exist_ok=True)
        print(f"   ğŸ“‚ ä¸­é—´è¿‡ç¨‹å°†ä¿å­˜åœ¨: {intermediates_dir}")
    
    # æ‰§è¡Œç”Ÿæˆ
    final_img, mask_img = pipeline.generate(
        args.poem, 
        seed=args.seed,
        save_intermediates_dir=intermediates_dir
    )
    
    if final_img:
        # ä¿å­˜
        save_path_img = os.path.join(args.output_dir, f"{safe_name}_paint.png")
        save_path_mask = os.path.join(args.output_dir, f"{safe_name}_mask.png")
        
        final_img.save(save_path_img)
        mask_img.save(save_path_mask)
        
        print(f"âœ… ç»“æœå·²ä¿å­˜:")
        print(f"   ç”»ä½œ: {save_path_img}")
        print(f"   æ©ç : {save_path_mask}")
        if intermediates_dir:
            print(f"   è¿‡ç¨‹: {intermediates_dir}/")

if __name__ == "__main__":
    main()